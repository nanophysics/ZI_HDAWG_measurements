{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\B15measure2\\anaconda3\\envs\\laboneq\\lib\\site-packages\\laboneq\\dsl\\device\\_device_setup_generator.py:1104: FutureWarning: 'instrument_list' section is deprecated in setup descriptor, use 'instruments' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023.08.24 10:51:51.766 laboneq.controller.laboneq_logging INFO   Logging initialized from [Default inline config in laboneq.controller.laboneq_logging] logdir is c:\\Users\\B15measure2\\ZI_HDAWG_measurements\\laboneq_output\\log\n",
      "2023.08.24 10:51:51.768 laboneq.controller.controller  INFO   VERSION: laboneq 2.11.0\n",
      "2023.08.24 10:51:51.771 laboneq.controller.devices.device_collection INFO   Connecting to data server at 127.0.0.1:8004\n",
      "2023.08.24 10:51:52.084 laboneq.controller.communication INFO   Connected to Zurich Instruments LabOne Data Server version 23.02 at 127.0.0.1:8004\n",
      "2023.08.24 10:51:53.023 laboneq.controller.devices.device_collection INFO   Configuring the device setup\n",
      "2023.08.24 10:51:53.207 laboneq.controller.devices.device_collection INFO   The device setup is configured\n",
      "[0.15 0.15]\n",
      "0.01\n",
      "Loaded exp\n",
      "2023.08.24 10:51:54.538 laboneq.compiler.workflow.compiler INFO   Starting LabOne Q Compiler run...\n",
      "2023.08.24 10:51:54.544 laboneq.compiler.scheduler.scheduler INFO   Schedule completed\n",
      "2023.08.24 10:52:24.688 laboneq.compiler.workflow.compiler INFO   Total seqC lines generated: 64\n",
      "2023.08.24 10:52:24.690 laboneq.compiler.workflow.compiler INFO   Total sample points generated: 384\n",
      "2023.08.24 10:52:24.691 laboneq.compiler.workflow.compiler INFO   Finished LabOne Q Compiler run.\n",
      "2023.08.24 10:52:24.999 laboneq.controller.devices.device_collection INFO   Configuring the device setup\n",
      "2023.08.24 10:52:25.185 laboneq.controller.devices.device_collection INFO   The device setup is configured\n",
      "2023.08.24 10:52:25.578 laboneq.controller.controller  INFO   Starting near-time execution...\n",
      "2023.08.24 10:52:28.909 laboneq.controller.controller  INFO   Finished near-time execution.\n",
      "Running exp finished\n",
      "[0.14 0.15]\n",
      "0.01\n",
      "Loaded exp\n",
      "2023.08.24 10:52:29.088 laboneq.compiler.workflow.compiler INFO   Starting LabOne Q Compiler run...\n",
      "2023.08.24 10:52:29.093 laboneq.compiler.scheduler.scheduler INFO   Schedule completed\n"
     ]
    }
   ],
   "source": [
    "#general imports\n",
    "%config IPCompleter.greedy=True \n",
    "import numpy as np\n",
    "import time\n",
    "import zhinst.core\n",
    "import laboneq\n",
    "from laboneq.simple import *\n",
    "import ctypes\n",
    "import helpers\n",
    "from picosdk.ps5000a import ps5000a as ps \n",
    "from picosdk.functions import adc2mV, assert_pico_ok#, mVadc (can't import for some reason) \n",
    "import picoscope_module as pm \n",
    "import configparser\n",
    "\n",
    "DO_EMULATION = False # run in emulation mode by default \n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config230823.ini')\n",
    "with open(config['DataPaths']['descriptor_path'], 'r') as file:\n",
    "    descriptor = file.read()\n",
    "\n",
    "# create and connect to session\n",
    "device_setup = DeviceSetup.from_descriptor(descriptor,server_host=\"127.0.0.1\",server_port=\"8004\", setup_name=\"ZI_HDAWG\")\n",
    "session = Session(device_setup=device_setup)\n",
    "session.connect(do_emulation=DO_EMULATION)\n",
    "if not session.connection_state.emulated:\n",
    "    instrument_serial = device_setup.instrument_by_uid(\"device_hdawg\").address\n",
    "    device = session.devices[instrument_serial]\n",
    "    device.triggers.out[2].delay(23.9e-9)\n",
    "\n",
    "#picoscope \n",
    "params = {key: float(value) for key, value in config['PicoscopeParameters'].items()}\n",
    "pico_sampling_rate = (params['timebase'] - 3) / 62500000\n",
    "preTriggerSamples=int(np.ceil(params['pretriggersamples']))\n",
    "postTriggerSamples = int(np.ceil(params['posttriggersamples_val'] / pico_sampling_rate))\n",
    "maxSamples = preTriggerSamples + postTriggerSamples\n",
    "\n",
    "NUM_REP = 50\n",
    "\n",
    "#defining parameters \n",
    "times_map = {\n",
    "    'unload_time': 10e-3, \n",
    "    'load_time': 10e-3, \n",
    "    'read_time': 10e-3, \n",
    "    'trigger_time': 1e-3\n",
    "}\n",
    "\n",
    "pulse_map = {\n",
    "    'unload': [-0.1,-0.1], \n",
    "    'load': [-0.1,0.1], \n",
    "\n",
    "}\n",
    "\n",
    "compress_level_pulse_unload_g1=pulse_library.const(uid=\"compress_level\",length=times_map['unload_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_unload_g2=pulse_library.const(uid=\"compress_level\",length=times_map['unload_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_load_g1=pulse_library.const(uid=\"compress_level\",length=times_map['load_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_load_g2=pulse_library.const(uid=\"compress_level\",length=times_map['load_time'],amplitude=1,can_compress=True)\n",
    "\n",
    "#reverse pulses\n",
    "compress_level_pulse_unload_g1_r=pulse_library.const(uid=\"compress_level\",length=times_map['unload_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_unload_g2_r=pulse_library.const(uid=\"compress_level\",length=times_map['unload_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_load_g1_r=pulse_library.const(uid=\"compress_level\",length=times_map['load_time'],amplitude=1,can_compress=True)\n",
    "compress_level_pulse_load_g2_r=pulse_library.const(uid=\"compress_level\",length=times_map['load_time'],amplitude=1,can_compress=True)\n",
    "\n",
    "chandle, status = pm.initialize_picoscope()\n",
    "status, chARange, chBRange = pm.setup_channels(chandle,status)\n",
    "status,maxADC = pm.setup_trigger(chandle, chARange, chBRange, params['triggerlevel'],status)\n",
    "\n",
    "# assign amplitude to received variable\n",
    "x_p = np.linspace(0.15, -0.1, 26)\n",
    "y_p = np.linspace(0.15, -0.1, 26)\n",
    "\n",
    "x_mesh, y_mesh = np.meshgrid(x_p, y_p)\n",
    "tensor_product = np.column_stack((x_mesh.ravel(), y_mesh.ravel()))\n",
    "\n",
    "#define pulse shapes\n",
    "#@pulse_library.register_pulse_functional\n",
    "#def ramp(x,start=0,stop=1,**_):\n",
    "#    pulse=start+ (stop-start)*(x+1)/2\n",
    "#    return pulse\n",
    "\n",
    "\n",
    "for received_variable in range(len(x_p)*len(y_p)):\n",
    "    read_amplitude=tensor_product[received_variable]\n",
    "    compress_level_pulse_read_g1=pulse_library.const(uid=\"compress_level\",length=times_map['read_time'],amplitude=1,can_compress=True)\n",
    "    compress_level_pulse_read_g2=pulse_library.const(uid=\"compress_level\",length=times_map['read_time'],amplitude=1,can_compress=True)\n",
    "    compress_level_pulse_read_g1_r=pulse_library.const(uid=\"compress_level\",length=times_map['read_time'],amplitude=1,can_compress=True)\n",
    "    compress_level_pulse_read_g2_r=pulse_library.const(uid=\"compress_level\",length=times_map['read_time'],amplitude=1,can_compress=True)\n",
    "    print(read_amplitude)\n",
    "    # Experiment\n",
    "    exp = Experiment(\n",
    "        \"Pulse Experiment\",\n",
    "        signals=[\n",
    "            ExperimentSignal(\"gate1\"),\n",
    "            ExperimentSignal(\"gate2\"),\n",
    "        ],\n",
    "    )\n",
    "    print(times_map['unload_time'])\n",
    "    with exp.acquire_loop_rt(\n",
    "        uid=(\"pulse\"), count=NUM_REP, averaging_mode=AveragingMode.SEQUENTIAL\n",
    "    ):\n",
    "        with exp.section(\n",
    "            uid=(\"unload\"),\n",
    "            length=times_map['unload_time'],\n",
    "            alignment=SectionAlignment.LEFT,\n",
    "        ):\n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_unload_g1, amplitude=pulse_map['unload'][0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_unload_g2,amplitude=pulse_map['unload'][1])\n",
    "\n",
    "        with exp.section(\n",
    "            uid=(\"load\"),\n",
    "            length=times_map['load_time'],\n",
    "            alignment=SectionAlignment.LEFT,\n",
    "            trigger={\"gate1\":{\"state\":1}}, \n",
    "        ):\n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_load_g1, amplitude=pulse_map['load'][0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_load_g2, amplitude=pulse_map['load'][1])\n",
    "\n",
    "        with exp.section(\n",
    "            uid=(\"measure\"),\n",
    "            length=times_map['read_time'],\n",
    "            alignment=SectionAlignment.LEFT, \n",
    "        ): \n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_read_g1, amplitude=read_amplitude[0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_read_g2, amplitude=read_amplitude[1])\n",
    "\n",
    "        with exp.section(\n",
    "            uid=(\"rev_measure\"),\n",
    "            length=times_map['read_time'],\n",
    "            alignment=SectionAlignment.LEFT, \n",
    "        ): \n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_read_g1_r, amplitude=-read_amplitude[0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_read_g2_r, amplitude=-read_amplitude[1])\n",
    "        \n",
    "        with exp.section(\n",
    "            uid=(\"rev_load\"),\n",
    "            length=times_map['load_time'],\n",
    "            alignment=SectionAlignment.LEFT,\n",
    "             \n",
    "        ):\n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_load_g1_r,amplitude=-pulse_map['load'][0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_load_g2_r,amplitude=-pulse_map['load'][1])\n",
    "\n",
    "        with exp.section(\n",
    "            uid=(\"rev_unload\"),\n",
    "            length=times_map['unload_time'],\n",
    "            alignment=SectionAlignment.LEFT,\n",
    "        ):\n",
    "            exp.play(signal=\"gate1\",pulse=compress_level_pulse_unload_g1_r, amplitude=-pulse_map['unload'][0])\n",
    "            exp.play(signal=\"gate2\",pulse=compress_level_pulse_unload_g2_r, amplitude=-pulse_map['unload'][1])\n",
    "\n",
    "\n",
    "    #shortcut to the logical signal group q0\n",
    "    lsg = device_setup.logical_signal_groups[\"q0\"].logical_signals\n",
    "\n",
    "    #define signal map\n",
    "    map_signals ={\n",
    "        \"gate1\" : lsg[\"fg4_line\"],\n",
    "        \"gate2\" : lsg[\"fg6_line\"]\n",
    "    }\n",
    "\n",
    "    noOfCaptures = NUM_REP\n",
    "    status,timeIntervalns = pm.capture_rapid_data_block(chandle, preTriggerSamples, postTriggerSamples, int(params['timebase']), maxSamples,noOfCaptures)\n",
    "\n",
    "\n",
    "    # set experiment calibration and signal map\n",
    "    exp.set_signal_map(map_signals)\n",
    "        \n",
    "    print(\"Loaded exp\")\n",
    "    session.run(exp)\n",
    "    print(\"Running exp finished\")\n",
    "\n",
    "    # # Check for data collection to finish using ps5000aIsReady\n",
    "    status = pm.check_ready(chandle, status)\n",
    "\n",
    "    source = ps.PS5000A_CHANNEL[\"PS5000A_CHANNEL_B\"]\n",
    "    buffersMax, buffersMin = pm.create_rapid_buffer(chandle, source, maxSamples, noOfCaptures)\n",
    "    pm.getValuesRapid(chandle,maxSamples,noOfCaptures)\n",
    "\n",
    "    # #postprocessing\n",
    "    # # convert ADC counts data to mV\n",
    "    cmaxSamples = ctypes.c_int32(maxSamples)\n",
    "\n",
    "    # # Create time data\n",
    "    time_stamp=int(time.time())\n",
    "    time_array = pm.create_time_data(maxSamples, timeIntervalns)\n",
    "    data_save_path = config['DataPaths']['data_save_path']\n",
    "    with open(f'{data_save_path}pulses_{time_stamp}_a={read_amplitude}.npy', 'wb') as f:\n",
    "        np.save(f,time_array)\n",
    "        for i in range(noOfCaptures):\n",
    "            np.save(f,adc2mV(buffersMax[i], chARange, maxADC))\n",
    "\n",
    "    with open(f'{data_save_path}config_{time_stamp}_a={read_amplitude}.txt', 'w') as f:\n",
    "        f.write(str(times_map)+'\\n')\n",
    "        f.write(str(pulse_map)+'\\n')\n",
    "        #Also include here later the whole pulse!!\n",
    "            \n",
    "    # Stop the scope\n",
    "    status = pm.stop_picoscope(chandle,status)\n",
    "\n",
    "    # Close unit Disconnect the scope \n",
    "pm.close_picoscope(chandle,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laboneq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
